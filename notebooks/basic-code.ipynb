{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitpytorch110condab050f83f33474bd49b114c64e9b47d9e",
   "display_name": "Python 3.8.5 64-bit ('pytorch-110': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Twitter Sentiment Analysis\n",
    "\n",
    "## Introduction\n",
    "  \n",
    "This tutorial explains a method to predict a sentiment of a twitt, in which it will be used RRNs as Deep Learning models. In general, the use of data in Social Networks is being exploited by the industry. For example, the analysis of sentiment of twits can be useful for a company that wants to analyse its new products. However, it is impossible that humans analyse each twit, therefore training deep learning models to predict is a way to scale the analysis.\n",
    "\n",
    "The data used in this tutorial comes from an investigation made from Stanford’s researchers. They have collected 1.4 millions of twits and classify them as positive or negative emotions based on emoticons written in the same twit, simulating Facebook. The table below contains the emotion category of the emoticon used. The data was downloaded by using the HugginFace API.\n",
    "  \n",
    "The structure of the tutorial is divided in three parts, and it will be explained: first, the steps to clean twits in order to have a dataset to do the predictions; second, the description and use of GloVe as a Word Embedding model; third, the use of LSTM in predicting sentiments. The idea of using RRNs is that sequence of words have information that can be used to predict the sentiment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "import random\n",
    "from torchtext.data import get_tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "## Load Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Reusing dataset sentiment140 (/home/nftd/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"sentiment140\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_twitts(data,twitt_n= 10000):\n",
    "    \"\"\"Read twitts.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    data : DatasetDict\n",
    "        Dataset loaded from hugginface\n",
    "    twitt_n : int\n",
    "        Number of twitts to use. This is to handle the use of memory\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    data_train : list\n",
    "        Train data\n",
    "    labels_train : list\n",
    "        Train label\n",
    "    data_test : list\n",
    "        Test data\n",
    "    labels_test : list\n",
    "        Test label\n",
    "    \"\"\"\n",
    "    set_ = 'train'\n",
    "    randomlist = random.sample(range(0, 1600000), twitt_n)\n",
    "    trainrandomlist = random.sample(randomlist,int(len(randomlist)*0.8))\n",
    "    testrandomlist = []\n",
    "    for index in randomlist:\n",
    "        if index not in trainrandomlist:\n",
    "            testrandomlist.append(index)\n",
    "    #training set\n",
    "    data_train, labels_train = [],[]\n",
    "    for i in trainrandomlist:\n",
    "        data_train.append(data[set_][i]['text'])\n",
    "        labels_train.append(data[set_][i]['sentiment'])\n",
    "    #test set\n",
    "    data_test, labels_test = [],[]\n",
    "    for i in testrandomlist:\n",
    "        data_test.append(data[set_][i]['text'])\n",
    "        labels_test.append(data[set_][i]['sentiment'])\n",
    "    return data_train,labels_train,data_test,labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label, test_data, test_label = read_twitts(dataset,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_info(data,label, k = 10):\n",
    "    print('# trainings:', len(data))\n",
    "    for x, y in zip(label[0:k], data[0:k]):\n",
    "        print('label:', x, 'review:', y)\n",
    "    for x, y in zip(label[-k:-1], data[-k:-1]):\n",
    "        print('label:', x, 'review:', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# trainings: 12800\nlabel: 4 review: 91 days till September 1st!!  #philwickham\nlabel: 0 review: oh great more problems with my macbook case cracking \nlabel: 0 review: WTF!I hate receptionist !Feels bad... \nlabel: 0 review: @JackAllTimeLow naww i would keep you company but ya know im not there  i'll see you tomorrow\nlabel: 0 review: 3 more followers, somebody unfollowed me \nlabel: 4 review: uber tired. should probably sleep now  ihave no idea why im still awake. &gt;.&lt;\nlabel: 4 review: Watching the da vinci code \nlabel: 0 review: my phone's gone for the whole summer break \nlabel: 0 review: Is not feeling good at all \nlabel: 0 review: whoooo hoooo i have 40 followers -.-&quot; -.-&quot;&quot; im so laaaaaaaaaame \nlabel: 0 review: Hate how my sources aren't getting back to me and one of the theaters closed! Stupid cut backs on theater in this county \nlabel: 4 review: new iphone tomorrow?  Can't wait...\nlabel: 0 review: I miss so many people, I could seriously make a list. That's bad!  Gotta re kindil those flames.\nlabel: 0 review: @savoragency Unfortunately, we couldn't stay, I was completely knocked out by the heat. \nlabel: 4 review: @candice5355 heyy  nothing, just listening to music. omj, got the new girlfriend and theres a double page on miley  but they said...\nlabel: 0 review: dang i have work in the morning \nlabel: 4 review: @mmaebseyy whats true? \nlabel: 0 review: god im tired today \nlabel: 4 review: @comicIDIOT Eh, I never liked Orkut... Maybe I should give it another look. \n"
     ]
    }
   ],
   "source": [
    "data_info(train_data,train_label)"
   ]
  },
  {
   "source": [
    "## Data cleaning\n",
    "In this section it will cover a step-by-step guide on how text can be cleaned, the objective is to transform the data into numbers so the models can be trained. It is necessary to understand the twit structure before designing a pipeline, below it is showed an example of a twit which was classified as negative:\n",
    "  \n",
    "> @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer. You shoulda got David Carr of Third Day to do it. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit = \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer. You shoulda got David Carr of Third Day to do it.\""
   ]
  },
  {
   "source": [
    "The steps to transform the data are the following:\n",
    "### Remove users\n",
    "This is a simple step; the objective is to identify words which contains an @ at their left side."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " http://twitpic.com/2y1zl - Awww, that's a bummer. You shoulda got David Carr of Third Day to do it.\n"
     ]
    }
   ],
   "source": [
    "def remove_user(txt):\n",
    "    return re.sub('@[^\\s]+','',txt)\n",
    "twit = remove_user(twit)\n",
    "print(twit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# trainings: 12800\nlabel: 4 review: 91 days till September 1st!!  #philwickham\nlabel: 0 review: oh great more problems with my macbook case cracking \nlabel: 0 review: WTF!I hate receptionist !Feels bad... \nlabel: 0 review:  naww i would keep you company but ya know im not there  i'll see you tomorrow\nlabel: 0 review: 3 more followers, somebody unfollowed me \nlabel: 4 review: uber tired. should probably sleep now  ihave no idea why im still awake. &gt;.&lt;\nlabel: 4 review: Watching the da vinci code \nlabel: 0 review: my phone's gone for the whole summer break \nlabel: 0 review: Is not feeling good at all \nlabel: 0 review: whoooo hoooo i have 40 followers -.-&quot; -.-&quot;&quot; im so laaaaaaaaaame \nlabel: 0 review: Hate how my sources aren't getting back to me and one of the theaters closed! Stupid cut backs on theater in this county \nlabel: 4 review: new iphone tomorrow?  Can't wait...\nlabel: 0 review: I miss so many people, I could seriously make a list. That's bad!  Gotta re kindil those flames.\nlabel: 0 review:  Unfortunately, we couldn't stay, I was completely knocked out by the heat. \nlabel: 4 review:  heyy  nothing, just listening to music. omj, got the new girlfriend and theres a double page on miley  but they said...\nlabel: 0 review: dang i have work in the morning \nlabel: 4 review:  whats true? \nlabel: 0 review: god im tired today \nlabel: 4 review:  Eh, I never liked Orkut... Maybe I should give it another look. \n"
     ]
    }
   ],
   "source": [
    "train_data_clean = [remove_user(i) for i in train_data]\n",
    "data_info(train_data_clean,train_label)"
   ]
  },
  {
   "source": [
    "### Remove URL\n",
    "Although hyperlink can have important information, it will take out from the text."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Awww thats a bummer You shoulda got David Carr of Third Day to do it\n"
     ]
    }
   ],
   "source": [
    "def remove_url(txt):\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "twit = remove_url(twit)\n",
    "print(twit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# trainings: 12800\nlabel: 4 review: 91 days till September 1st philwickham\nlabel: 0 review: oh great more problems with my macbook case cracking\nlabel: 0 review: WTFI hate receptionist Feels bad\nlabel: 0 review: naww i would keep you company but ya know im not there ill see you tomorrow\nlabel: 0 review: 3 more followers somebody unfollowed me\nlabel: 4 review: uber tired should probably sleep now ihave no idea why im still awake gtlt\nlabel: 4 review: Watching the da vinci code\nlabel: 0 review: my phones gone for the whole summer break\nlabel: 0 review: Is not feeling good at all\nlabel: 0 review: whoooo hoooo i have 40 followers quot quotquot im so laaaaaaaaaame\nlabel: 0 review: Hate how my sources arent getting back to me and one of the theaters closed Stupid cut backs on theater in this county\nlabel: 4 review: new iphone tomorrow Cant wait\nlabel: 0 review: I miss so many people I could seriously make a list Thats bad Gotta re kindil those flames\nlabel: 0 review: Unfortunately we couldnt stay I was completely knocked out by the heat\nlabel: 4 review: heyy nothing just listening to music omj got the new girlfriend and theres a double page on miley but they said\nlabel: 0 review: dang i have work in the morning\nlabel: 4 review: whats true\nlabel: 0 review: god im tired today\nlabel: 4 review: Eh I never liked Orkut Maybe I should give it another look\n"
     ]
    }
   ],
   "source": [
    "train_data_clean = [remove_url(i) for i in train_data_clean]\n",
    "data_info(train_data_clean,train_label)"
   ]
  },
  {
   "source": [
    "### Tokenize\n",
    "Tokenize means that the words in the text will be split by a delimiter, normalize by a function and put the words in a list. In our case, it will split the words by spaces and it will transform to undercase all of the words. It will be used the function “get_tokenizer” from torchtext. The result are tokens and an example it is showed below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['awww', 'thats', 'a', 'bummer', 'you', 'shoulda', 'got', 'david', 'carr', 'of', 'third', 'day', 'to', 'do', 'it']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "print(tokenizer(twit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# trainings: 12800\nlabel: 4 review: ['91', 'days', 'till', 'september', '1st', 'philwickham']\nlabel: 0 review: ['oh', 'great', 'more', 'problems', 'with', 'my', 'macbook', 'case', 'cracking']\nlabel: 0 review: ['wtfi', 'hate', 'receptionist', 'feels', 'bad']\nlabel: 0 review: ['naww', 'i', 'would', 'keep', 'you', 'company', 'but', 'ya', 'know', 'im', 'not', 'there', 'ill', 'see', 'you', 'tomorrow']\nlabel: 0 review: ['3', 'more', 'followers', 'somebody', 'unfollowed', 'me']\nlabel: 4 review: ['uber', 'tired', 'should', 'probably', 'sleep', 'now', 'ihave', 'no', 'idea', 'why', 'im', 'still', 'awake', 'gtlt']\nlabel: 4 review: ['watching', 'the', 'da', 'vinci', 'code']\nlabel: 0 review: ['my', 'phones', 'gone', 'for', 'the', 'whole', 'summer', 'break']\nlabel: 0 review: ['is', 'not', 'feeling', 'good', 'at', 'all']\nlabel: 0 review: ['whoooo', 'hoooo', 'i', 'have', '40', 'followers', 'quot', 'quotquot', 'im', 'so', 'laaaaaaaaaame']\nlabel: 0 review: ['hate', 'how', 'my', 'sources', 'arent', 'getting', 'back', 'to', 'me', 'and', 'one', 'of', 'the', 'theaters', 'closed', 'stupid', 'cut', 'backs', 'on', 'theater', 'in', 'this', 'county']\nlabel: 4 review: ['new', 'iphone', 'tomorrow', 'cant', 'wait']\nlabel: 0 review: ['i', 'miss', 'so', 'many', 'people', 'i', 'could', 'seriously', 'make', 'a', 'list', 'thats', 'bad', 'gotta', 're', 'kindil', 'those', 'flames']\nlabel: 0 review: ['unfortunately', 'we', 'couldnt', 'stay', 'i', 'was', 'completely', 'knocked', 'out', 'by', 'the', 'heat']\nlabel: 4 review: ['heyy', 'nothing', 'just', 'listening', 'to', 'music', 'omj', 'got', 'the', 'new', 'girlfriend', 'and', 'theres', 'a', 'double', 'page', 'on', 'miley', 'but', 'they', 'said']\nlabel: 0 review: ['dang', 'i', 'have', 'work', 'in', 'the', 'morning']\nlabel: 4 review: ['whats', 'true']\nlabel: 0 review: ['god', 'im', 'tired', 'today']\nlabel: 4 review: ['eh', 'i', 'never', 'liked', 'orkut', 'maybe', 'i', 'should', 'give', 'it', 'another', 'look']\n"
     ]
    }
   ],
   "source": [
    "train_data_token = [tokenizer(i) for i in train_data_clean]\n",
    "data_info(train_data_token,train_label)"
   ]
  },
  {
   "source": [
    "### Drop empty twits\n",
    "This step is simple, after the transformations it can be found twits without tokens. Hence, all empty lists will be dropped, within their labels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_tweets(data, label):\n",
    "    data_non_empty = []\n",
    "    label_non_empty = []\n",
    "    empty_twitt = 0\n",
    "    for i, tweet in enumerate(data):\n",
    "        if len(tweet) > 0:\n",
    "            data_non_empty.append(tweet)\n",
    "            label_non_empty.append(label[i])\n",
    "        else:\n",
    "            empty_twitt += 1\n",
    "    print(f\"There were {empty_twitt} empty twitts\")\n",
    "    return data_non_empty,label_non_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There were 27 empty twitts\n"
     ]
    }
   ],
   "source": [
    "train_data_non_empty,train_label_non_empty = drop_empty_tweets(train_data_token,train_label)"
   ]
  },
  {
   "source": [
    "### Convert label\n",
    "The frequency of each sentiment label is shown below. The label `4` correspond to a positive sentiment, while `0` is a negative sentiment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    6417\n",
       "4    6356\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "pd.Series(train_label_non_empty).value_counts()"
   ]
  },
  {
   "source": [
    "This means that we are facing with balanced classes, hence there is no need to specify weights in the loss function. However, the Neural Networks is set to predict {0,1}. Therefore, this is easy to solve by changing the label `4` to `1`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(label):\n",
    "    train_label_conv = []\n",
    "    for i in train_label:\n",
    "        if i == 4:\n",
    "            train_label_conv.append(1)\n",
    "        else:\n",
    "            train_label_conv.append(0)\n",
    "    return train_label_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_converted = convert_labels(train_label_non_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}